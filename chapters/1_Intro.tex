% !TeX root = ../main.tex

\chapter{绪论}

\section{研究背景}

作为计算机图形学的一个分支，渲染是将用不同表达表示的几何、材质、光照、相机等信息综合，然后最终生成二维图像的过程。根据一幅图像渲染时间来分类，计算机图形学领域通常将渲染技术分为实时渲染和离线渲染两个大类。对于实时渲染来说，实时性是需要保证的重要性能指标，而这一般意味着绘制帧率需要达到每秒 30 幅画面或更高。

利用专用的 GPU 和光栅化图形管线来进行实时渲染是目前的主流方案。这种方案将实时渲染过程抽象为以顶点输入，顶点着色，光栅化，片段着色和深度模板测试为阶段的管线过程。为了方便对不同厂商生产的 GPU 进行编程，设备和操作系统厂商间约定了比较稳定的图形 API，例如现在由 Khronos Group 负责的 OpenGL，OpenGL ES，Vulkan，由 Microsoft 公司负责的 Direct3D 和由 Apple 负责的 Metal 等。

早期的图形管线设计多以固定管线功能为主，图形程序员只能够操作管线功能的开启和关闭，并不能像自己编写程序一样对顶点和片段颜色等进行管线预设功能之外的操作。随着图形硬件的功能演进，OpenGL 和 Direct3D 均加入了通过图形程序员编写的专用程序片段来替换部分固定管线的实现的功能。这样的专用程序片段被称为着色器程序 (Shader Program)。

对于现代图形 API 来说，着色器程序本身以 HLSL，GLSL 等高层次描述语言写就，并在程序运行时呈递给设备厂商或操作系统厂商提供的驱动程序中的编译器进行运行时编译。多种多样的着色器程序极大的丰富了光栅化图形管线可以实现的图形和图像效果，成为了现在游戏、VR 等交互式互动娱乐应用程序编写时的重要组成部分。

为了适应实时渲染在各种类型终端上的广泛需求， GPU 市场十分丰富。对于桌面端，就有 Intel, AMD, NVIDIA, Apple 等公司提供 GPU 解决方案；而如 Qualcomm，Broadcom，Imagination，华为等公司则提供移动端的 GPU 和 IP 解决方案。这些 GPU 家族，包括其各自每代的处理器设计，通常拥有不同的指令集架构 (Instruction Set Architecture, ISA)，微架构等，而仅仅在图形 API 的层次上做到对使用者一致。例如，桌面端的 GPU 普遍支持 Direct3D，Vulkan，OpenGL 等图形 API，移动端的 GPU 则普遍支持 OpenGL ES, Vulkan 等图形 API。对于应用开发者来说，设备厂商通过图形 API 层来努力隔离设备之间的异质性。

然而，这种隔离并不是充分的。不同的架构和单元配置会影响 GPU 执行用户负载时的性能，而这种性能上的区别会对最终用户的体验产生或多或少的影响。在所有图形程序的性能影响因素中，着色器程序因其可编程性，会对性能产生较大的影响。因此，本文围绕着光栅化图形管线中的着色器程序，研究其性能的预测问题。

\section{挑战与研究内容}

针对于 GPU 上应用的性能预测和优化问题，业界已经开发出多种工具和方法。以 Radeon Graphics Profiler\cite{AMDRGP} 和 NSight Graphics\cite{NSightGraphics} 为例，它们会通过一次或多次专门的管线性能剖析过程，利用 GPU 内部的性能计数器给出着色器的优化建议。此外，诸如 Emerald 和 GPGPU-Sim 这样的体系结构模拟器，则通过对 GPU 架构的模拟和较精确的建模来预测着色器的性能。然而，上述方法和工具的局限性在于，其依赖于特定的厂商或 GPU 架构，且需要在每一种 GPU 上进行单独测试或专门的模拟运行。这样一来，在高度分散的 GPU 市场中，这种特性要求开发者对每一种平台都进行单独的建模或性能分析，增加了额外的测试和调优负担。

在着色器优化和简化问题过程中，学术界曾有相关研究对待优化的着色器性能进行建模。然而，这些工作主要采用较简单的性能估算方法，比如认为着色器的运行时间和着色器中进行的标量运算以及纹理访问操作次数成正比。然而，着色器指令的执行时间受到多种因素的影响。这些影响因素包括编译器优化和 GPU 架构特点，如缓存系统设计和运算单元的数量等。因此，这些未能充分考虑这些因素的模型，往往不能准确预测性能表现。

基于上面的观察，本文主要提出了一种利用神经网络，针对不同 GPU 平台上图形管线中着色器的性能进行建模和预测的方法。利用基于神经网络的学习方法，本文提出的方法可以较为简便的应用到不同 GPU 平台上，达到平台无关性。同时，通过利用神经网络对着色器程序进行学习， GPU 架构特点和程序负载特征等和程序性能相关的因素也被考虑了进来，从而可以进一步的提高预测准确度。

具体来看，为了对本文提出的方法进行验证，我们收集了来自 Shadertoy 的 27911 个着色器程序，在五个平台收集了总计 54667 个性能样本，并将其作为我们的着色器程序性能数据集。同时，本文所述的方法还实现了在 SPIR-V 着色器中间表示上插桩，从而获得每个 SPIR-V 指令的执行计数，并作为上下文信息输入预测器。同时，为了将程序中的指令作为一个序列整体加以考虑，本文所属的预测方法采用 Transformer 编码器来进行序列学习。

\section{章节安排}

本文的章节安排大致如下：

第一章主要介绍本研究的研究背景、研究意义，挑战和研究的大致内容。

第二章主要介绍本研究相关的背景知识。本研究主要和着色器程序优化，程序语言理解和程序性能建模三个方面相关。

第三章主要介绍本研究提出的，基于神经网络的着色器程序性能预测方法。该章首先给出本方法的总览，随后分别介绍本方法较核心的三部分的设计，分别为着色器程序性能数据集的程序收集、测量和评估方法，基本块粒度的 SPIR-V 指令追踪的程序编排和实现，以及本方法提出的神经网络性能模型。最后，本章给出了上面提到的部分的分析和验证实验。

第四章给出了本研究的工作总结和展望。